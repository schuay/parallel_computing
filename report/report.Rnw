\documentclass[a4paper,10pt]{article}

\usepackage{comment}
\usepackage[pdfborder={0 0 0}]{hyperref}
\usepackage[utf8]{inputenc}

\title{Introduction to Parallel Computing, WS 2012}
\author{
    Jakob Gruber, 0203440 \\
    Mino Sharkhawy, 1025887
}

\begin{comment}
A useful Sweave tutorial can be found at http://users.stat.umn.edu/~geyer/Sweave/.

Short report, 1-3 pages (depending) per project plus
performance plots (1-5 pages). Be ready to discuss this at
presentation, also program code

Be concise, clear, brief:
•What you have done
•How you tested (main test cases, problems encountered)
•What you have not done (assumption like: „the program
assumes p is even“, „n must be a power of two“, ...)
•Be honest – things that don‘t work
•What you intend to show with the experiments

Note will be based on presentation/discussion, and hand-in.

Criteria:
•Correctness, by argument (e.g. merging, prefix-sums), and test
•Well chosen test cases, in principle exhaustive, show that you
have thought about what needs to be tested
•Program actually working, given stated restrictions
•Good plots/tables showing the properties (speed-up, work) of
the implementations
•Achieved performance improvement – don‘t be too depressed if
speed-up is modest and less than p
\end{comment}

\begin{document}

\maketitle

\clearpage
\tableofcontents

\clearpage
\section{OpenMP}

\subsection{Parallel Prefix Sums}

\subsubsection{Specification}

Implement the 3 parallel prefix sums algorithms from the lecture:

\begin{enumerate}
\item Recursive parallel prefix with auxiliary array y
\item In-place iterative algorithm
\item O(nlog n) work algorithm (Hillis-Steele)
\end{enumerate}

All algorithms shall work on arrays of some basetype given at compile time
(int, double, ...) with the ``+'' operator.
Implement non-intrusive ``performance counters'' for documenting that the work
is indeed O(n) and O(n log n).
The implementations shall be correct for all array sizes n, and any number of
threads, 1,...,max.
Test and benchmark the implementations, for OpenMP compare performance to
``reduction'' clause.

\subsubsection{Results}

<<results=tex,echo=FALSE>>=
REF <- "sequential reference"
fidx <- 0

texPlot <- function(x, y, pch, text, xlab, ylab, main, log) {
	file=paste("graph", fidx, ".eps", sep="")  
	fidx <<- fidx + 1

	postscript(file=file, paper="special", width=8, height=8, horizontal=FALSE)  

	matplot(x,y, pch=pch, type='b', xlab=xlab, ylab=ylab, main=main, log=log)
	legend("topleft", text, col=pch, pch=pch)

	dev.off()  

	cat("\\includegraphics{", file, "}\n\n", sep="")
}

plotByNumThreads <- function(par, seq, prefix) {
	pars <- split(par, par[,1])
	pch <- 1:length(pars)
	addPar <- function(p) {
		if (nrow(p) > 0) {
			x <<- cbind(x,p[,3])
			y <<- cbind(y,p[,4])
			nThreads <<- p[1,2]
			txt <<- c(txt,as.character(p[1,1]))
		}
	}
	nThreads <- 1
	txt <- REF
	x <- seq[,3]
	y <- seq[,4]
	sapply(pars, FUN=addPar)

	texPlot(x,y, pch, txt, "input size", "time(s)", sprintf("%s: Time as function of input size (%d thread(s))", prefix, nThreads), "xy")
}

plotByInputSize <- function(par, prefix) {
	pars <- split(par, par[,1])
	pch <- 1:(length(pars)-1)
	addPar <- function(p) {
		if (nrow(p) > 0) {
			x <<- cbind(x,p[,2])
			y <<- cbind(y,p[,4])
			nInput <<- p[1,3]
			txt <<- c(txt,as.character(p[1,1]))
		}
	}
	nInput <- 1
	txt <- NULL
	x <- NULL
	y <- NULL
	sapply(pars, FUN=addPar)

	texPlot(x,y, pch, txt, "number of threads", "time(s)", sprintf("%s: Time as function of the number of threads (input size = %d)", prefix, nInput), "")
}

makePlots <- function(times, prefix) {
	ref <- times[times[,1] == REF,]
	pars <- times[times[,1] != REF,]
	byNumThreads <- split(pars, pars[,2])
	byInputSize <- split(pars, pars[,3])
	unused <- sapply(byNumThreads, FUN=plotByNumThreads, ref, prefix)
	unused <- sapply(byInputSize, FUN=plotByInputSize, prefix)
}

readAndPlot <- function(file) {
	results <- read.table(file, sep=",")

	time_mean <- aggregate(results[,4], by=list(results[,1],results[,2],results[,3]), FUN=mean)
	time_best <- aggregate(results[,4], by=list(results[,1],results[,2],results[,3]), FUN=min)

	unused <- makePlots(time_mean, "Avg")
	unused <- makePlots(time_best, "Min")
}

readAndPlot("../1-prefix_sums/data/bench.csv")

@

\clearpage
\subsection{A Work-Optimal Merge Algorithm}

\subsubsection{Specification}

Implement a work-optimal merge algorithm for merging two
sorted arrays of size n and m in O((m+n)/p+log n +log m) steps.
The implementation shall work for all n and m, any C base
datatype, but may assume that elements in the two array are all
different

Implement either:

\begin{enumerate}
\item binary search from block starts of array a into array b. Merge (in
parallel) all pairs no larger than (m+n)/p; handle larger pairs by binary
search from array b to a
\item binary search from block starts of a and block starts of b. Describe
briefly the special cases for the binary search for locating subarrays, and how
this leads to all sub- merge problems having size O(n/p+m/p)
\end{enumerate}

Argue for correctness by testing. Benchmark and compare to standard, sequential
merge implementation from lecture (or better one, if known), report speed-up

\subsubsection{Results}

<<results=tex,echo=FALSE>>=
readAndPlot("../1-merge/data/bench.csv")
@

\clearpage
\section{Cilk}

\subsection{Task-Parallel vs. Data-Parallel Merge Algorithms}

\clearpage
\section{MPI}

\subsection{Parallel Stencil Computation}

\clearpage
\subsection{Parallel Integer Bucket Sort}

\clearpage
\subsection{...}

\end{document}
